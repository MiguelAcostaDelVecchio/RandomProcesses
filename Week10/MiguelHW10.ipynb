{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import pandas\n",
    "import numpy as np\n",
    "from scipy.special import gamma, psi\n",
    "from scipy import ndimage\n",
    "from scipy.linalg import det\n",
    "from numpy import pi\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy given a 5 coin flip experiment and p = 0.5 is  1.0\n"
     ]
    }
   ],
   "source": [
    "p = 0.5\n",
    "e5 = (-p*math.log2(p))-((1-p)*math.log2(1-p))\n",
    "\n",
    "print(f\"Entropy given a 5 coin flip experiment and p = 0.5 is \", e5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2\n",
    "\n",
    "In my github at: https://github.com/MiguelAcostaDelVecchio/RandomProcesses/tree/master/Week10\n",
    "\n",
    "The file name is Question2.pdf\n",
    "\n",
    "## Question 3\n",
    "\n",
    "In my github at: https://github.com/MiguelAcostaDelVecchio/RandomProcesses/tree/master/Week10\n",
    "\n",
    "The file name is Question3.pdf\n",
    "\n",
    "## Question 4\n",
    "\n",
    "In my github at: https://github.com/MiguelAcostaDelVecchio/RandomProcesses/tree/master/Week10\n",
    "\n",
    "The file name is Question4.pdf\n",
    "\n",
    "## Question 5\n",
    "\n",
    "In my github at: https://github.com/MiguelAcostaDelVecchio/RandomProcesses/tree/master/Week10\n",
    "\n",
    "The file name is Question5.pdf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "outputs": [],
   "source": [
    "p = 0.24\n",
    "\n",
    "a = -p*math.log2(p)\n",
    "#print(a)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "outputs": [],
   "source": [
    "p = 0.11\n",
    "b = 0.17\n",
    "c = 0.56\n",
    "\n",
    "a = p*math.log2(p/(b*c))\n",
    "#print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "outputs": [],
   "source": [
    "#print(\"Importing the data...\")\n",
    "dataFrame = pandas.read_csv('hw10_data.csv')\n",
    "\n",
    "x = dataFrame[\"x\"].to_numpy()\n",
    "y = dataFrame[\"y\"].to_numpy()\n",
    "x = x.reshape(len(x),1)\n",
    "y = y.reshape(len(y),1)\n",
    "#print(x[0:5])\n",
    "#print(y[0:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "outputs": [],
   "source": [
    "def nearest_distances(X, k=1):\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(X)\n",
    "    d, _ = knn.kneighbors(X)  # the first nearest neighbor is itself\n",
    "    return d[:, -1]  # returns the distance to the kth nearest neighbor\n",
    "\n",
    "def entropy(X, k=1):\n",
    "\n",
    "    # Distance to kth nearest neighbor\n",
    "    r = nearest_distances(X, k)  # squared distances\n",
    "    n, d = X.shape\n",
    "    volume_unit_ball = (pi ** (.5 * d)) / gamma(.5 * d + 1)\n",
    "    return (d * np.mean(np.log(r + np.finfo(X.dtype).eps)) +\n",
    "            np.log(volume_unit_ball) + psi(n) - psi(k))\n",
    "\n",
    "\n",
    "def mutual_information(variables, k=1):\n",
    "    if len(variables) < 2:\n",
    "        raise AttributeError(\n",
    "            \"Mutual information must involve at least 2 variables\")\n",
    "    all_vars = np.hstack(variables)\n",
    "    return (sum([entropy(X, k=k) for X in variables]) -\n",
    "            entropy(all_vars, k=k))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mutual information between random variable x and y is:  7.726035335820839\n"
     ]
    }
   ],
   "source": [
    "print(\"The mutual information between random variable x and y is: \", mutual_information((x,y)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}